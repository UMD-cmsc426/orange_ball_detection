{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import testGMM\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# parameters:\n",
    "# k: int, number of guassian distribution\n",
    "# max_iter: int, maximum number of step in optimization\n",
    "# img_name: strings, the relative path to single image, i.e. \"train_images/032.jpg\"\n",
    "def trainGMM(K, max_iter, img_name):\n",
    "    # read img\n",
    "    img = cv2.imread(img_name)\n",
    "    # user defined converge threshold\n",
    "    tau = 0.00000000000000001\n",
    "\n",
    "    def initialize():\n",
    "        random_w = random.randint(0,img.shape[0])\n",
    "        random_h = random.randint(0,img.shape[1])\n",
    "        mean = [[img[random_w][random_h][0]],[img[random_w][random_h][1]],[img[random_w][random_h][2]]]\n",
    "        # generate a random positive-semidefinete matrix as covariance matrix\n",
    "        A = np.random.randint(1,5,(3,3))\n",
    "        cov = np.dot(A, A.transpose())\n",
    "        scaling = random.random() * 5.0\n",
    "        return [scaling,mean,cov]\n",
    "\n",
    "    params = [initialize() for cluster in range(K)]\n",
    "    # Structure of para:\n",
    "    # [[scale,mean,covariance],[scale,mean,covariance],[scale,mean,covariance]...]\n",
    "    # scale is a int. Mean is a 3x1 matrix. Covariance is a 3x3 matrix\n",
    "\n",
    "    # total_mean is the sum of all mean from different clusters\n",
    "    total_mean = np.full((K,3, 3), -9999)\n",
    "    prev_total_mean = np.full((K,3, 3), 9999)\n",
    "    iter = 0\n",
    "\n",
    "    # return true if MLE converges. Return false otherwise\n",
    "    def check_convergence(total_mean, prev_toal_mean, tau):\n",
    "        sum = 0\n",
    "        for cluster in range(len(prev_toal_mean)):\n",
    "            sum += np.linalg.norm(total_mean[cluster]-prev_total_mean[cluster])\n",
    "        print(\"Check convergence difference: \", sum)\n",
    "        return sum <= tau\n",
    "\n",
    "    while iter <= max_iter and check_convergence(total_mean,prev_total_mean,tau):\n",
    "        # update prev total mean\n",
    "        prev_total_mean = total_mean\n",
    "\n",
    "        # Expectation step - assign points to clusters, get cluster weight\n",
    "        weights = []\n",
    "        for cluster in range(K):\n",
    "            # weight for a single cluster\n",
    "            cluster_weights = np.zeros((img.shape[0], img.shape[1]))\n",
    "            # cumulated weights add up all weights on a given pixel -- serving as denominator\n",
    "            cumulated_weights = np.zeros((img.shape[0], img.shape[1]))\n",
    "            cluster_scaling, cluster_mean, cluster_cov = params[cluster]\n",
    "\n",
    "            for w in range(len(img[:, 0, 0])):\n",
    "                for h in range(len(img[0, :, 0])):\n",
    "                    pix = np.asmatrix([[img[w][h][0]], [img[w][h][1]], [img[w][h][2]]])\n",
    "                    likelihood = testGMM.get_likelihood(pix, cluster_mean, cluster_cov)\n",
    "\n",
    "                    ## calculate weight at position (w, h)\n",
    "                    weight = cluster_scaling * likelihood\n",
    "                    cumulated_weights[w][h] += weight\n",
    "                    cluster_weights[w][h] = weight # probability of each pixel belonging to this cluster\n",
    "\n",
    "            weights.append(cluster_weights) # weights for all clusters 1 to K,\n",
    "            #weights[i][w][h]is the probability of the (w,h) pixel belonging to the ith cluster\n",
    "        for cluster in range(K):\n",
    "            weights[cluster] = np.divide(weights[cluster], cumulated_weights)\n",
    "\n",
    "        # Maximization step - get new scaling, mean, and cov for each cluster\n",
    "        for cluster in range(K):\n",
    "            mean_sum = np.zeros((3,1)) # sums all weight*pixel RGB value on image\n",
    "            cov_sum = np.zeros((3,3))\n",
    "            sum_weights = np.sum(weights[cluster]) # sum of all the weights given a cluster\n",
    "            for w in range(len(img[:, 0, 0])):\n",
    "                for h in range(len(img[0, :, 0])):\n",
    "                    pix = np.asmatrix([[img[w][h][0]], [img[w][h][1]], [img[w][h][2]]])\n",
    "                    # calculate mean\n",
    "                    mean_sum += np.multiply(weights[cluster][w][h],pix)\n",
    "\n",
    "            new_mean = np.divide(mean_sum, sum_weights)\n",
    "\n",
    "            for w in range(len(img[:, 0, 0])):\n",
    "                for h in range(len(img[0, :, 0])):\n",
    "                    pix = np.asmatrix([[img[w][h][0]], [img[w][h][1]], [img[w][h][2]]])\n",
    "                    # calculate covariance\n",
    "                    cov_sum += np.multiply(weights[cluster][w][h], (pix - new_mean))@((pix - new_mean).T)\n",
    "            new_cov = np.divide(cov_sum, sum_weights)\n",
    "            new_scaling = sum_weights / (img.shape[0]*img.shape[1])\n",
    "            mean_sum += mean_sum\n",
    "\n",
    "            total_mean[cluster] = new_mean\n",
    "            print()\n",
    "            # update model\n",
    "            params[cluster] = (new_scaling, new_mean, new_cov)\n",
    "        print(\"iter: \", iter)\n",
    "        iter += 1\n",
    "    # store weights to .npy\n",
    "    if not os.path.exists(\"weights\"):\n",
    "        os.mkdir(\"weights\")\n",
    "    else:\n",
    "        digit = re.findall(r'\\d+\\d+\\d*',img_name)\n",
    "        file_name = str(digit[0])+\"_weight.npy\"\n",
    "        with open(os.path.join(\"weights\",file_name), \"wb\") as f:\n",
    "            np.save(f,params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check convergence difference:  299970.0\n",
      "Finish Training for  train_images\\106.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Miniconda3\\envs\\cmsc426\\lib\\site-packages\\numpy\\core\\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"train_images\"\n",
    "for img_name in os.listdir(input_dir):\n",
    "    img = os.path.join(input_dir, img_name)\n",
    "    trainGMM(5,200,img)\n",
    "    print(\"Finish Training for \", img)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% testing below\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Miniconda3\\envs\\cmsc426\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "p = np.asarray([0,[[2],[4],[6]],[[1,2,3],[4,5,6],[7,8,9]]])\n",
    "name = \"train_images/68.jpg\"\n",
    "digit = re.findall(r'\\d+\\d+\\d*',name)\n",
    "file_name = str(digit[0])+\"_weight.npy\"\n",
    "with open(os.path.join(\"weights\",file_name), \"wb\") as f:\n",
    "    np.save(f,p)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n"
     ]
    }
   ],
   "source": [
    "with open('weights/68_weight.npy', 'rb') as f:\n",
    "    a = np.load(f, allow_pickle=True)\n",
    "    print(a[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [3, 4], [7, 8]]\n"
     ]
    }
   ],
   "source": [
    "A = [[1,2],[3,4],[5,6]]\n",
    "A[2] = [7,8]\n",
    "print(A)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-64c552b2",
   "language": "python",
   "display_name": "PyCharm (homework1)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}